{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can better understand what features the ABCNN model is learning by looking at its attention distributions.\n",
    "\n",
    "The attention distributions for the ABCNN-1 blocks can help us to understand word and phrasal associations between sequences that the model is finding.\n",
    "\n",
    "First, we import the necessary modules for the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model.attention.utils import manhattan\n",
    "from model.attention.utils import euclidean\n",
    "from model.attention.utils import cosine\n",
    "from model.attention.utils import compute_attention_matrix\n",
    "from setup import read_config\n",
    "from setup import setup_datasets_and_model\n",
    "from utils import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"config.json\"\n",
    "CHECKPOINT_FILE = \"checkpoints/gpu0/best_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Notebook, we'll use a pre-trained ABCNN-3 models. We will also need to load in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283003/283003 [00:41<00:00, 6787.33it/s]\n",
      "100%|██████████| 41238/41238 [00:06<00:00, 6696.95it/s]\n",
      "100%|██████████| 80049/80049 [00:11<00:00, 6997.46it/s]\n",
      "100%|██████████| 86001/86001 [00:00<00:00, 523412.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load in the datasets and a model\n",
    "config = read_config(CONFIG_FILE)\n",
    "datasets, model = setup_datasets_and_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the pre-trained model loaded and the datasets, the first thing we can do is inspect the attention matrices themselves for a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite model weights with pre-trained weights\n",
    "state = load_checkpoint(CHECKPOINT_FILE)\n",
    "model_dict, optim_dict, _, _ = state\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
